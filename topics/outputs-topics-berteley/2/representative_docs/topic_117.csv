doc
experimental design regret minimization linear bandit paper propose novel experimental design base algorithm minimize regret online stochastic linear combinatorial bandit existing literature tend focus optimism base algorithm show suboptimal case approach carefully plan action balance tradeoff information gain reward overcome failure optimism addition leverage tool theory suprema empirical process obtain regret guarantee scale gaussian width action set avoid wasteful union bound provide state art finite time regret guarantee algorithm apply bandit semi bandit feedback regime combinatorial semi bandit setting algorithm computationally efficient rely call linear maximization oracle addition slight modification algorithm pure exploration obtain state art pure exploration guarantee semi bandit setting finally provide good knowledge example optimism fail semi bandit regime set algorithm succeed
survey contextual multi armed bandit survey cover stochastic adversarial contextual bandit algorithm analyze algorithm assumption regret bind
smooth contextual bandit bridge parametric non differentiable regret regime study nonparametric contextual bandit problem expect reward function belong class smoothness parameter interpolate extreme previously study isolation non differentiable bandit rate optimal regret achieve run separate non contextual bandit different context region parametric response bandit satisfy rate optimal regret achieve minimal exploration infinite extrapolatability develop novel algorithm carefully adjust smoothness setting prove regret rate optimal establish match upper low bound recover exist result extreme sense work bridge gap exist literature parametric non differentiable contextual bandit problem bandit algorithm exclusively use global local information shed light crucial interplay complexity regret contextual bandit
