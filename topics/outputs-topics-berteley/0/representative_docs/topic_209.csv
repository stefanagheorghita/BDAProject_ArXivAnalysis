doc
"language models in molecular discovery. the success of language models, especially transformer-based architectures, has trickled into other domains giving rise to ""scientific language models"" that operate on small molecules, proteins or polymers. in chemistry, language models contribute to accelerating the molecule discovery cycle as evidenced by promising recent findings in early-stage drug discovery. here, we review the role of language models in molecular discovery, underlining their strength in de novo drug design, property prediction and reaction chemistry. we highlight valuable open-source software assets thus lowering the entry barrier to the field of scientific language modeling. last, we sketch a vision for future molecular design that combines a chatbot interface with access to computational chemistry tools. our contribution serves as a valuable resource for researchers, chemists, and ai enthusiasts interested in understanding how language models can and will be used to accelerate chemical discovery."
"chem3dllm: 3d multimodal large language models for chemistry. in the real world, a molecule is a 3d geometric structure. compared to 1d smiles sequences and 2d molecular graphs, 3d molecules represent the most informative molecular modality. despite the rapid progress of autoregressive-based language models, they cannot handle the generation of 3d molecular conformation due to several challenges: 1) 3d molecular structures are incompatible with llms' discrete token space, 2) integrating heterogeneous inputs like proteins, ligands, and text remains difficult within a unified model, and 3) llms lack essential scientific priors, hindering the enforcement of physical and chemical constraints during generation. to tackle these issues, we present chem3dllm, a unified protein-conditioned multimodal large language model. our approach designs a novel reversible text encoding for 3d molecular structures using run-length compression, achieving 3x size reduction while preserving complete structural information. this enables seamless integration of molecular geometry with protein pocket features in a single llm architecture. we employ reinforcement learning with stability-based rewards to optimize chemical validity and incorporate a lightweight protein embedding projector for end-to-end training. experimental results on structure-based drug design demonstrate state-of-the-art performance with a vina score of -7.21, validating our unified multimodal approach for practical drug discovery applications."
"hyperbolic molecular representation learning for drug repositioning. learning accurate drug representations is essential for task such as computational drug repositioning. a drug hierarchy is a valuable source that encodes knowledge of relations among drugs in a tree-like structure where drugs that act on the same organs, treat the same disease, or bind to the same biological target are grouped together. however, its utility in learning drug representations has not yet been explored, and currently described drug representations cannot place novel molecules in a drug hierarchy. here, we develop a semi-supervised drug embedding that incorporates two sources of information: (1) underlying chemical grammar that is inferred from chemical structures of drugs and drug-like molecules (unsupervised), and (2) hierarchical relations that are encoded in an expert-crafted hierarchy of approved drugs (supervised). we use the variational auto-encoder (vae) framework to encode the chemical structures of molecules and use the drug-drug similarity information obtained from the hierarchy to induce the clustering of drugs in hyperbolic space. the hyperbolic space is amenable for encoding hierarchical relations. our qualitative results support that the learned drug embedding can induce the hierarchical relations among drugs. we demonstrate that the learned drug embedding can be used for drug repositioning."
