doc
"probing commonsense knowledge in pre-trained language models with sense-level precision and expanded vocabulary. progress on commonsense reasoning is usually measured from performance improvements on question answering tasks designed to require commonsense knowledge. however, fine-tuning large language models (lms) on these specific tasks does not directly evaluate commonsense learned during pre-training. the most direct assessments of commonsense knowledge in pre-trained lms are arguably cloze-style tasks targeting commonsense assertions (e.g., a pen is used for [mask].). however, this approach is restricted by the lm's vocabulary available for masked predictions, and its precision is subject to the context provided by the assertion. in this work, we present a method for enriching lms with a grounded sense inventory (i.e., wordnet) available at the vocabulary level, without further training. this modification augments the prediction space of cloze-style prompts to the size of a large ontology while enabling finer-grained (sense-level) queries and predictions. in order to evaluate lms with higher precision, we propose senselama, a cloze-style task featuring verbalized relations from disambiguated triples sourced from wordnet, wikidata, and conceptnet. applying our method to bert, producing a wordnet-enriched version named synbert, we find that lms can learn non-trivial commonsense knowledge from self-supervision, covering numerous relations, and more effectively than comparable similarity-based approaches."
"revisiting generative commonsense reasoning: a pre-ordering approach. pre-trained models (ptms) have lead to great improvements in natural language generation (nlg). however, it is still unclear how much commonsense knowledge they possess. with the goal of evaluating commonsense knowledge of nlg models, recent work has proposed the problem of generative commonsense reasoning, e.g., to compose a logical sentence given a set of unordered concepts. existing approaches to this problem hypothesize that ptms lack sufficient parametric knowledge for this task, which can be overcome by introducing external knowledge or task-specific pre-training objectives. different from this trend, we argue that ptm's inherent ability for generative commonsense reasoning is underestimated due to the order-agnostic property of its input. in particular, we hypothesize that the order of the input concepts can affect the ptm's ability to utilize its commonsense knowledge. to this end, we propose a pre-ordering approach to elaborately manipulate the order of the given concepts before generation. experiments show that our approach can outperform the more sophisticated models that have access to a lot of external data and resources."
"cider: commonsense inference for dialogue explanation and reasoning. commonsense inference to understand and explain human language is a fundamental research problem in natural language processing. explaining human conversations poses a great challenge as it requires contextual understanding, planning, inference, and several aspects of reasoning including causal, temporal, and commonsense reasoning. in this work, we introduce cider -- a manually curated dataset that contains dyadic dialogue explanations in the form of implicit and explicit knowledge triplets inferred using contextual commonsense inference. extracting such rich explanations from conversations can be conducive to improving several downstream applications. the annotated triplets are categorized by the type of commonsense knowledge present (e.g., causal, conditional, temporal). we set up three different tasks conditioned on the annotated dataset: dialogue-level natural language inference, span extraction, and multi-choice span selection. baseline results obtained with transformer-based models reveal that the tasks are difficult, paving the way for promising future research. the dataset and the baseline implementations are publicly available at https://cider-task.github.io/cider/."
