doc
"diffusionstr: diffusion model for scene text recognition. this paper presents diffusion model for scene text recognition (diffusionstr), an end-to-end text recognition framework using diffusion models for recognizing text in the wild. while existing studies have viewed the scene text recognition task as an image-to-text transformation, we rethought it as a text-text one under images in a diffusion model. we show for the first time that the diffusion model can be applied to text recognition. furthermore, experimental results on publicly available datasets show that the proposed method achieves competitive accuracy compared to state-of-the-art methods."
"step -- towards structured scene-text spotting. we introduce the structured scene-text spotting task, which requires a scene-text ocr system to spot text in the wild according to a query regular expression. contrary to generic scene text ocr, structured scene-text spotting seeks to dynamically condition both scene text detection and recognition on user-provided regular expressions. to tackle this task, we propose the structured text spotter (step), a model that exploits the provided text structure to guide the ocr process. step is able to deal with regular expressions that contain spaces and it is not bound to detection at the word-level granularity. our approach enables accurate zero-shot structured text spotting in a wide variety of real-world reading scenarios and is solely trained on publicly available data. to demonstrate the effectiveness of our approach, we introduce a new challenging test dataset that contains several types of out-of-vocabulary structured text, reflecting important reading applications of fields such as prices, dates, serial numbers, license plates etc. we demonstrate that step can provide specialised ocr performance on demand in all tested scenarios."
"chinese text in the wild. we introduce chinese text in the wild, a very large dataset of chinese text in street view images. while optical character recognition (ocr) in document images is well studied and many commercial tools are available, detection and recognition of text in natural images is still a challenging problem, especially for more complicated character sets such as chinese text. lack of training data has always been a problem, especially for deep learning methods which require massive training data. in this paper we provide details of a newly created dataset of chinese text with about 1 million chinese characters annotated by experts in over 30 thousand street view images. this is a challenging dataset with good diversity. it contains planar text, raised text, text in cities, text in rural areas, text under poor illumination, distant text, partially occluded text, etc. for each character in the dataset, the annotation includes its underlying character, its bounding box, and 6 attributes. the attributes indicate whether it has complex background, whether it is raised, whether it is handwritten or printed, etc. the large size and diversity of this dataset make it suitable for training robust neural networks for various tasks, particularly detection and recognition. we give baseline results using several state-of-the-art networks, including alexnet, overfeat, google inception and resnet for character recognition, and yolov2 for character detection in images. overall google inception has the best performance on recognition with 80.5% top-1 accuracy, while yolov2 achieves an map of 71.0% on detection. dataset, source code and trained models will all be publicly available on the website."
