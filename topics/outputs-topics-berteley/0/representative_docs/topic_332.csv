doc
"time-lapse image classification using a diffractive neural network. diffractive deep neural networks (d2nns) define an all-optical computing framework comprised of spatially engineered passive surfaces that collectively process optical input information by modulating the amplitude and/or the phase of the propagating light. diffractive optical networks complete their computational tasks at the speed of light propagation through a thin diffractive volume, without any external computing power while exploiting the massive parallelism of optics. diffractive networks were demonstrated to achieve all-optical classification of objects and perform universal linear transformations. here we demonstrate, for the first time, a ""time-lapse"" image classification scheme using a diffractive network, significantly advancing its classification accuracy and generalization performance on complex input objects by using the lateral movements of the input objects and/or the diffractive network, relative to each other. in a different context, such relative movements of the objects and/or the camera are routinely being used for image super-resolution applications; inspired by their success, we designed a time-lapse diffractive network to benefit from the complementary information content created by controlled or random lateral shifts. we numerically explored the design space and performance limits of time-lapse diffractive networks, revealing a blind testing accuracy of 62.03% on the optical classification of objects from the cifar-10 dataset. this constitutes the highest inference accuracy achieved so far using a single diffractive network on the cifar-10 dataset. time-lapse diffractive networks will be broadly useful for the spatio-temporal analysis of input signals using all-optical processors."
"all-optical machine learning using diffractive deep neural networks. we introduce an all-optical diffractive deep neural network (d2nn) architecture that can learn to implement various functions after deep learning-based design of passive diffractive layers that work collectively. we experimentally demonstrated the success of this framework by creating 3d-printed d2nns that learned to implement handwritten digit classification and the function of an imaging lens at terahertz spectrum. with the existing plethora of 3d-printing and other lithographic fabrication methods as well as spatial-light-modulators, this all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can implement, and will find applications in all-optical image analysis, feature detection and object classification, also enabling new camera designs and optical components that can learn to perform unique tasks using d2nns."
"class-specific differential detection in diffractive optical neural networks improves inference accuracy. diffractive deep neural networks have been introduced earlier as an optical machine learning framework that uses task-specific diffractive surfaces designed by deep learning to all-optically perform inference, achieving promising performance for object classification and imaging. here we demonstrate systematic improvements in diffractive optical neural networks based on a differential measurement technique that mitigates the non-negativity constraint of light intensity. in this scheme, each class is assigned to a separate pair of photodetectors, behind a diffractive network, and the class inference is made by maximizing the normalized signal difference between the detector pairs. moreover, by utilizing the inherent parallelization capability of optical systems, we reduced the signal coupling between the positive and negative detectors of each class by dividing their optical path into two jointly-trained diffractive neural networks that work in parallel. we further made use of this parallelization approach, and divided individual classes among multiple jointly-trained differential diffractive neural networks. using this class-specific differential detection in jointly-optimized diffractive networks, our simulations achieved testing accuracies of 98.52%, 91.48% and 50.82% for mnist, fashion-mnist and grayscale cifar-10 datasets, respectively. similar to ensemble methods practiced in machine learning, we also independently-optimized multiple differential diffractive networks that optically project their light onto a common detector plane, and achieved testing accuracies of 98.59%, 91.06% and 51.44% for mnist, fashion-mnist and grayscale cifar-10, respectively. through these systematic advances in designing diffractive neural networks, the reported classification accuracies set the state-of-the-art for an all-optical neural network design."
