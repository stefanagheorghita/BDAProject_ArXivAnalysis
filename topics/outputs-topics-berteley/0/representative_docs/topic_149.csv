doc
"a simple yet effective baseline for 3d human pose estimation. following the success of deep convolutional networks, state-of-the-art methods for 3d human pose estimation have focused on deep end-to-end systems that predict 3d joint locations given raw image pixels. despite their excellent performance, it is often not easy to understand whether their remaining error stems from a limited 2d pose (visual) understanding, or from a failure to map 2d poses into 3-dimensional positions. with the goal of understanding these sources of error, we set out to build a system that given 2d joint locations predicts 3d positions. much to our surprise, we have found that, with current technology, ""lifting"" ground truth 2d joint locations to 3d space is a task that can be solved with a remarkably low error rate: a relatively simple deep feed-forward network outperforms the best reported result by about 30\% on human3.6m, the largest publicly available 3d pose estimation benchmark. furthermore, training our system on the output of an off-the-shelf state-of-the-art 2d detector (\ie, using images as input) yields state of the art results -- this includes an array of systems that have been trained end-to-end specifically for this task. our results indicate that a large portion of the error of modern deep 3d pose estimation systems stems from their visual analysis, and suggests directions to further advance the state of the art in 3d human pose estimation."
"synthesizing training images for boosting human 3d pose estimation. human 3d pose estimation from a single image is a challenging task with numerous applications. convolutional neural networks (cnns) have recently achieved superior performance on the task of 2d pose estimation from a single image, by training on images with 2d annotations collected by crowd sourcing. this suggests that similar success could be achieved for direct estimation of 3d poses. however, 3d poses are much harder to annotate, and the lack of suitable annotated training images hinders attempts towards end-to-end solutions. to address this issue, we opt to automatically synthesize training images with ground truth pose annotations. our work is a systematic study along this road. we find that pose space coverage and texture diversity are the key ingredients for the effectiveness of synthetic training data. we present a fully automatic, scalable approach that samples the human pose space for guiding the synthesis procedure and extracts clothing textures from real images. furthermore, we explore domain adaptation for bridging the gap between our synthetic training images and real testing photos. we demonstrate that cnns trained with our synthetic images out-perform those trained with real photos on 3d pose estimation tasks."
"lcr-net++: multi-person 2d and 3d pose detection in natural images. we propose an end-to-end architecture for joint 2d and 3d human pose estimation in natural images. key to our approach is the generation and scoring of a number of pose proposals per image, which allows us to predict 2d and 3d poses of multiple people simultaneously. hence, our approach does not require an approximate localization of the humans for initialization. our localization-classification-regression architecture, named lcr-net, contains 3 main components: 1) the pose proposal generator that suggests candidate poses at different locations in the image; 2) a classifier that scores the different pose proposals; and 3) a regressor that refines pose proposals both in 2d and 3d. all three stages share the convolutional feature layers and are trained jointly. the final pose estimation is obtained by integrating over neighboring pose hypotheses, which is shown to improve over a standard non maximum suppression algorithm. our method recovers full-body 2d and 3d poses, hallucinating plausible body parts when the persons are partially occluded or truncated by the image boundary. our approach significantly outperforms the state of the art in 3d pose estimation on human3.6m, a controlled environment. moreover, it shows promising results on real images for both single and multi-person subsets of the mpii 2d pose benchmark and demonstrates satisfying 3d pose results even for multi-person images."
