doc
"ethical implications of ai in data collection: balancing innovation with privacy. this article examines the ethical and legal implications of artificial intelligence (ai) driven data collection, focusing on developments from 2023 to 2024. it analyzes recent advancements in ai technologies and their impact on data collection practices across various sectors. the study compares regulatory approaches in the european union, the united states, and china, highlighting the challenges in creating a globally harmonized framework for ai governance. key ethical issues, including informed consent, algorithmic bias, and privacy protection, are critically assessed in the context of increasingly sophisticated ai systems. the research explores case studies in healthcare, finance, and smart cities to illustrate the practical challenges of ai implementation. it evaluates the effectiveness of current legal frameworks and proposes solutions encompassing legal and policy recommendations, technical safeguards, and ethical frameworks. the article emphasizes the need for adaptive governance and international cooperation to address the global nature of ai development while balancing innovation with the protection of individual rights and societal values."
"trustworthy ai: from principles to practices. the rapid development of artificial intelligence (ai) technology has enabled the deployment of various systems based on it. however, many current ai systems are found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection. these shortcomings degrade user experience and erode people's trust in all ai systems. in this review, we provide ai practitioners with a comprehensive guide for building trustworthy ai systems. we first introduce the theoretical framework of important aspects of ai trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, and accountability. to unify currently available but fragmented approaches toward trustworthy ai, we organize them in a systematic approach that considers the entire lifecycle of ai systems, ranging from data acquisition to model development, to system development and deployment, finally to continuous monitoring and governance. in this framework, we offer concrete action items for practitioners and societal stakeholders (e.g., researchers, engineers, and regulators) to improve ai trustworthiness. finally, we identify key opportunities and challenges for the future development of trustworthy ai systems, where we identify the need for a paradigm shift toward comprehensively trustworthy ai systems."
"a five-layer framework for ai governance: integrating regulation, standards, and certification. purpose: the governance of artificial iintelligence (ai) systems requires a structured approach that connects high-level regulatory principles with practical implementation. existing frameworks lack clarity on how regulations translate into conformity mechanisms, leading to gaps in compliance and enforcement. this paper addresses this critical gap in ai governance. methodology/approach: a five-layer ai governance framework is proposed, spanning from broad regulatory mandates to specific standards, assessment methodologies, and certification processes. by narrowing its scope through progressively focused layers, the framework provides a structured pathway to meet technical, regulatory, and ethical requirements. its applicability is validated through two case studies on ai fairness and ai incident reporting. findings: the case studies demonstrate the framework's ability to identify gaps in legal mandates, standardization, and implementation. it adapts to both global and region-specific ai governance needs, mapping regulatory mandates with practical applications to improve compliance and risk management. practical implications - by offering a clear and actionable roadmap, this work contributes to global ai governance by equipping policymakers, regulators, and industry stakeholders with a model to enhance compliance and risk management. social implications: the framework supports the development of policies that build public trust and promote the ethical use of ai for the benefit of society. originality/value: this study proposes a five-layer ai governance framework that bridges high-level regulatory mandates and implementation guidelines. validated through case studies on ai fairness and incident reporting, it identifies gaps such as missing standardized assessment procedures and reporting mechanisms, providing a structured foundation for targeted governance measures."
