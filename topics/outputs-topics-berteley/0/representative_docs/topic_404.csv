doc
parallel computing of discrete element method on gpu. we investigate applicability of gpu to dem. nvidia's code obtained superior performance than cpu in computational time. a model of contact forces in nvidia's code is too simple for practical use. we modify this model by replacing it with the practical model. the simulation shows that the practical model obtains the computing speed 6 times faster than the practical one on cpu while 7 times slower than the simple one on gpu. the result are analyzed.
"three dimensional pseudo-spectral compressible magnetohydrodynamic gpu code for astrophysical plasma simulation. this paper presents the benchmarking and scaling studies of a gpu accelerated three dimensional compressible magnetohydrodynamic code. the code is developed keeping an eye to explain the large and intermediate scale magnetic field generation is cosmos as well as in nuclear fusion reactors in the light of the theory given by eugene newman parker. the spatial derivatives of the code are pseudo-spectral method based and the time solvers are explicit. gpu acceleration is achieved with minimal code changes through openacc parallelization and use of nvidia cuda fast fourier transform library (cufft). nvidias unified memory is leveraged to enable over-subscription of the gpu device memory for seamless out-of-core processing of large grids. our experimental results indicate that the gpu accelerated code is able to achieve upto two orders of magnitude speedup over a corresponding openmp parallel, fftw library based code, on a nvidia tesla p100 gpu. for large grids that require out-of-core processing on the gpu, we see a 7x speedup over the openmp, fftw based code, on the tesla p100 gpu. we also present performance analysis of the gpu accelerated code on different gpu architectures - kepler, pascal and volta."
"gamer: a gpu-accelerated adaptive mesh refinement code for astrophysics. we present the newly developed code, gamer (gpu-accelerated adaptive mesh refinement code), which has adopted a novel approach to improve the performance of adaptive mesh refinement (amr) astrophysical simulations by a large factor with the use of the graphic processing unit (gpu). the amr implementation is based on a hierarchy of grid patches with an oct-tree data structure. we adopt a three-dimensional relaxing tvd scheme for the hydrodynamic solver, and a multi-level relaxation scheme for the poisson solver. both solvers have been implemented in gpu, by which hundreds of patches can be advanced in parallel. the computational overhead associated with the data transfer between cpu and gpu is carefully reduced by utilizing the capability of asynchronous memory copies in gpu, and the computing time of the ghost-zone values for each patch is made to diminish by overlapping it with the gpu computations. we demonstrate the accuracy of the code by performing several standard test problems in astrophysics. gamer is a parallel code that can be run in a multi-gpu cluster system. we measure the performance of the code by performing purely-baryonic cosmological simulations in different hardware implementations, in which detailed timing analyses provide comparison between the computations with and without gpu(s) acceleration. maximum speed-up factors of 12.19 and 10.47 are demonstrated using 1 gpu with 4096^3 effective resolution and 16 gpus with 8192^3 effective resolution, respectively."
