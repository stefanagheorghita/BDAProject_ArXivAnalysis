doc
"deep generative adversarial residual convolutional networks for real-world super-resolution. most current deep learning based single image super-resolution (sisr) methods focus on designing deeper / wider models to learn the non-linear mapping between low-resolution (lr) inputs and the high-resolution (hr) outputs from a large number of paired (lr/hr) training data. they usually take as assumption that the lr image is a bicubic down-sampled version of the hr image. however, such degradation process is not available in real-world settings i.e. inherent sensor noise, stochastic noise, compression artifacts, possible mismatch between image degradation process and camera device. it reduces significantly the performance of current sisr methods due to real-world image corruptions. to address these problems, we propose a deep super-resolution residual convolutional generative adversarial network (srrescgan) to follow the real-world degradation settings by adversarial training the model with pixel-wise supervision in the hr domain from its generated lr counterpart. the proposed network exploits the residual learning by minimizing the energy-based objective function with powerful image regularization and convex optimization techniques. we demonstrate our proposed approach in quantitative and qualitative experiments that generalize robustly to real input and it is easy to deploy for other down-scaling operators and mobile/embedded devices."
"real image super-resolution using gan through modeling of lr and hr process. the current existing deep image super-resolution methods usually assume that a low resolution (lr) image is bicubicly downscaled of a high resolution (hr) image. however, such an ideal bicubic downsampling process is different from the real lr degradations, which usually come from complicated combinations of different degradation processes, such as camera blur, sensor noise, sharpening artifacts, jpeg compression, and further image editing, and several times image transmission over the internet and unpredictable noises. it leads to the highly ill-posed nature of the inverse upscaling problem. to address these issues, we propose a gan-based sr approach with learnable adaptive sinusoidal nonlinearities incorporated in lr and sr models by directly learn degradation distributions and then synthesize paired lr/hr training data to train the generalized sr model to real image degradations. we demonstrate the effectiveness of our proposed approach in quantitative and qualitative experiments."
"dual reconstruction nets for image super-resolution with gradient sensitive loss. deep neural networks have exhibited promising performance in image super-resolution (sr) due to the power in learning the non-linear mapping from low-resolution (lr) images to high-resolution (hr) images. however, most deep learning methods employ feed-forward architectures, and thus the dependencies between lr and hr images are not fully exploited, leading to limited learning performance. moreover, most deep learning based sr methods apply the pixel-wise reconstruction error as the loss, which, however, may fail to capture high-frequency information and produce perceptually unsatisfying results, whilst the recent perceptual loss relies on some pre-trained deep model and they may not generalize well. in this paper, we introduce a mask to separate the image into low- and high-frequency parts based on image gradient magnitude, and then devise a gradient sensitive loss to well capture the structures in the image without sacrificing the recovery of low-frequency content. moreover, by investigating the duality in sr, we develop a dual reconstruction network (drn) to improve the sr performance. we provide theoretical analysis on the generalization performance of our method and demonstrate its effectiveness and superiority with thorough experiments."
