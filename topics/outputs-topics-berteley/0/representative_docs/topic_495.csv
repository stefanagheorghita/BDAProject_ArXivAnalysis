doc
"hatebench: benchmarking hate speech detectors on llm-generated content and hate campaigns. large language models (llms) have raised increasing concerns about their misuse in generating hate speech. among all the efforts to address this issue, hate speech detectors play a crucial role. however, the effectiveness of different detectors against llm-generated hate speech remains largely unknown. in this paper, we propose hatebench, a framework for benchmarking hate speech detectors on llm-generated hate speech. we first construct a hate speech dataset of 7,838 samples generated by six widely-used llms covering 34 identity groups, with meticulous annotations by three labelers. we then assess the effectiveness of eight representative hate speech detectors on the llm-generated dataset. our results show that while detectors are generally effective in identifying llm-generated hate speech, their performance degrades with newer versions of llms. we also reveal the potential of llm-driven hate campaigns, a new threat that llms bring to the field of hate speech detection. by leveraging advanced techniques like adversarial attacks and model stealing attacks, the adversary can intentionally evade the detector and automate hate campaigns online. the most potent adversarial attack achieves an attack success rate of 0.966, and its attack efficiency can be further improved by $13-21\times$ through model stealing attacks with acceptable attack performance. we hope our study can serve as a call to action for the research community and platform moderators to fortify defenses against these emerging threats."
"highly generalizable models for multilingual hate speech detection. hate speech detection has become an important research topic within the past decade. more private corporations are needing to regulate user generated content on different platforms across the globe. in this paper, we introduce a study of multilingual hate speech classification. we compile a dataset of 11 languages and resolve different taxonomies by analyzing the combined data with binary labels: hate speech or not hate speech. defining hate speech in a single way across different languages and datasets may erase cultural nuances to the definition, therefore, we utilize language agnostic embeddings provided by laser and muse in order to develop models that can use a generalized definition of hate speech across datasets. furthermore, we evaluate prior state of the art methodologies for hate speech detection under our expanded dataset. we conduct three types of experiments for a binary hate speech classification task: multilingual-train monolingual-test, monolingualtrain monolingual-test and language-family-train monolingual test scenarios to see if performance increases for each language due to learning more from other language data."
"dealing with annotator disagreement in hate speech classification. hate speech detection is a crucial task, especially on social media, where harmful content can spread quickly. implementing machine learning models to automatically identify and address hate speech is essential for mitigating its impact and preventing its proliferation. the first step in developing an effective hate speech detection model is to acquire a high-quality dataset for training. labeled data is essential for most natural language processing tasks, but categorizing hate speech is difficult due to the diverse and often subjective nature of hate speech, which can lead to varying interpretations and disagreements among annotators. this paper examines strategies for addressing annotator disagreement, an issue that has been largely overlooked. in particular, we evaluate various automatic approaches for aggregating multiple annotations, in the context of hate speech classification in turkish tweets. our work highlights the importance of the problem and provides state-of-the-art benchmark results for the detection and understanding of hate speech in online discourse."
