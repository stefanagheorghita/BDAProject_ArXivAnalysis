doc
"exploring distortion prior with latent diffusion models for remote sensing image compression. deep learning-based image compression algorithms typically focus on designing encoding and decoding networks and improving the accuracy of entropy model estimation to enhance the rate-distortion (rd) performance. however, few algorithms leverage the compression distortion prior from existing compression algorithms to improve rd performance. in this paper, we propose a latent diffusion model-based remote sensing image compression (ldm-rsic) method, which aims to enhance the final decoding quality of rs images by utilizing the generated distortion prior from a ldm. our approach consists of two stages. in the first stage, a self-encoder learns prior from the high-quality input image. in the second stage, the prior is generated through an ldm, conditioned on the decoded image of an existing learning-based image compression algorithm, to be used as auxiliary information for generating the texture-rich enhanced image. to better utilize the prior, a channel attention and gate-based dynamic feature attention module (dfam) is embedded into a transformer-based multi-scale enhancement network (men) for image enhancement. extensive experiments demonstrate the proposed ldm-rsic significantly outperforms existing state-of-the-art traditional and learning-based image compression algorithms in terms of both subjective perception and objective metrics. additionally, we use the ldm-based scheme to improve the traditional image compression algorithm jpeg2000 and obtain 32.00% bit savings on the dota testing set. the code will be available at https://github.com/mlkk518/ldm-rsic."
"exploiting inter-image similarity prior for low-bitrate remote sensing image compression. deep learning-based methods have garnered significant attention in remote sensing (rs) image compression due to their superior performance. most of these methods focus on enhancing the coding capability of the compression network and improving entropy model prediction accuracy. however, they typically compress and decompress each image independently, ignoring the significant inter-image similarity prior. in this paper, we propose a codebook-based rs image compression (code-rsic) method with a generated discrete codebook, which is deployed at the decoding end of a compression algorithm to provide inter-image similarity prior. specifically, we first pretrain a high-quality discrete codebook using the competitive generation model vqgan. we then introduce a transformer-based prediction model to align the latent features of the decoded images from an existing compression algorithm with the frozen high-quality codebook. finally, we develop a hierarchical prior integration network (hpin), which mainly consists of transformer blocks and multi-head cross-attention modules (mcms) that can query hierarchical prior from the codebook, thus enhancing the ability of the proposed method to decode texture-rich rs images. extensive experimental results demonstrate that the proposed code-rsic significantly outperforms state-of-the-art traditional and learning-based image compression algorithms in terms of perception quality. the code will be available at \url{https://github.com/mlkk518/code-rsic/"
"image coding for machines with object region learning. compression technology is essential for efficient image transmission and storage. with the rapid advances in deep learning, images are beginning to be used for image recognition as well as for human vision. for this reason, research has been conducted on image coding for image recognition, and this field is called image coding for machines (icm). there are two main approaches in icm: the roi-based approach and the task-loss-based approach. the former approach has the problem of requiring an roi-map as input in addition to the input image. the latter approach has the problems of difficulty in learning the task-loss, and lack of robustness because the specific image recognition model is used to compute the loss function. to solve these problems, we propose an image compression model that learns object regions. our model does not require additional information as input, such as an roi-map, and does not use task-loss. therefore, it is possible to compress images for various image recognition models. in the experiments, we demonstrate the versatility of the proposed method by using three different image recognition models and three different datasets. in addition, we verify the effectiveness of our model by comparing it with previous methods."
