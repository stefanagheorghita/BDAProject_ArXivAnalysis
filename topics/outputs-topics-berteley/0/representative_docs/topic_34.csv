doc
survey bug ai generate code developer widely ai code generation model aim increase productivity efficiency quality concern ai generate code generate code produce model train publicly available code know contain bug quality issue issue cause trust maintenance challenge development process quality issue associate ai generate code report include bug defect finding scatter lack systematic summary comprehensive review currently lack reveal type distribution error possible remediation strategy correlation specific model paper systematically analyze exist ai generate code literature establish overall understanding bug defect generate code provide reference future model improvement quality assessment aim understand nature extent bug ai generate code provide classification bug type pattern present code generate different model discuss possible fix mitigation strategy adopt eliminate bug generate code
trust code copilot evaluate large language model code security perspective code security usability essential cod assistant application drive large language model llm current code security benchmark focus solely single evaluation task paradigm code completion generation lack comprehensive assessment dimension like secure code generation vulnerability repair discrimination paper propose cov eval multi task benchmark cover task code completion vulnerability repair vulnerability detection classification comprehensive evaluation llm code security develop vc judge improved judgment model align closely human expert review llm generate program vulnerability efficient reliable way conduct comprehensive evaluation proprietary open source llm overall llm identify vulnerable code tend generate insecure code struggle recognize specific vulnerability type perform repair extensive experiment qualitative analysis reveal key challenge optimization direction offer insight future research llm code security
survey evaluate large language model code generation task paper provide comprehensive review current method metric evaluate performance large language model llm code generation task rapid growth demand automate software development llm demonstrate significant potential field code generation paper begin review historical development llm application code generation detail method metric assess code generation capability llm include code correctness efficiency readability evaluation method base expert review user experience paper evaluate widely benchmark dataset identify limitation propose direction future improvement specifically paper analyze performance code generation model different task combine multiple evaluation metric code compilation interpretation success rate unit test pass rate performance efficiency metric comprehensively assess practical application llm code generation finally paper discuss challenge face evaluate llm code generation particularly ensure comprehensiveness accuracy evaluation method adapt evolve practice software development analysis discussion provide valuable insight optimize improve application llm code generation task
