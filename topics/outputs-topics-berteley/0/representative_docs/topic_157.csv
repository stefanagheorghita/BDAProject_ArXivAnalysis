doc
"wide-area land cover mapping with sentinel-1 imagery using deep learning semantic segmentation models. land cover mapping is essential to monitoring the environment and understanding the effects of human activities on it. the automatic approaches to land cover mapping (i.e., image segmentation) mostly used traditional machine learning that requires heuristic feature design. on natural images, deep learning has outperformed traditional machine learning approaches for image segmentation. on remote sensing images, recent studies demonstrate successful applications of specific deep learning models to small-scale land cover mapping tasks (e.g., to classify wetland complexes). however, it is not readily clear which of the existing models are the best candidates for which remote sensing task. in this study, we answer that question for mapping the fundamental land cover classes using satellite radar data. we took sentinel-1 c-band sar images available at no cost to users as representative data. corine land cover map was used as a reference, and the models were trained to distinguish between the 5 major corine classes. we selected seven among the state-of-the-art semantic segmentation models so that they cover a diverse set of approaches: u-net, deeplabv3+, pspnet, bisenet, segnet, fc-densenet, and frrn-b. the models were pre-trained on the imagenet dataset and further fine-tuned in this study. all the models demonstrated solid performance with overall accuracy between 87.9% and 93.1%, and with good to a very good agreement (kappa statistic between 0.75 and 0.86). the two best models were fc-densenet and segnet, with the latter having a much smaller inference time. overall, our results indicate that the semantic segmentation models are suitable for efficient wide-area mapping using satellite sar imagery and also provide baseline accuracy against which the newly proposed models should be evaluated."
"learning from noisy pseudo-labels for all-weather land cover mapping. semantic segmentation of sar images has garnered significant attention in remote sensing due to the immunity of sar sensors to cloudy weather and light conditions. nevertheless, sar imagery lacks detailed information and is plagued by significant speckle noise, rendering the annotation or segmentation of sar images a formidable task. recent efforts have resorted to annotating paired optical-sar images to generate pseudo-labels through the utilization of an optical image segmentation network. however, these pseudo-labels are laden with noise, leading to suboptimal performance in sar image segmentation. in this study, we introduce a more precise method for generating pseudo-labels by incorporating semi-supervised learning alongside a novel image resolution alignment augmentation. furthermore, we introduce a symmetric cross-entropy loss to mitigate the impact of noisy pseudo-labels. additionally, a bag of training and testing tricks is utilized to generate better land-cover mapping results. our experiments on the grss data fusion contest indicate the effectiveness of the proposed method, which achieves first place. the code is available at https://github.com/stuliu/dfc2025track1.git."
"sarnet: a dataset for deep learning assisted search and rescue with satellite imagery. access to high resolution satellite imagery has dramatically increased in recent years as several new constellations have entered service. high revisit frequencies as well as improved resolution has widened the use cases of satellite imagery to areas such as humanitarian relief and even search and rescue (sar). we propose a novel remote sensing object detection dataset for deep learning assisted sar. this dataset contains only small objects that have been identified as potential targets as part of a live sar response. we evaluate the application of popular object detection models to this dataset as a baseline to inform further research. we also propose a novel object detection metric, specifically designed to be used in a deep learning assisted sar setting."
