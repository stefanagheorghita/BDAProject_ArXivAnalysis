doc
"cafa: global weather forecasting with factorized attention on sphere. accurate weather forecasting is crucial in various sectors, impacting decision-making processes and societal events. data-driven approaches based on machine learning models have recently emerged as a promising alternative to numerical weather prediction models given their potential to capture physics of different scales from historical data and the significantly lower computational cost during the prediction stage. renowned for its state-of-the-art performance across diverse domains, the transformer model has also gained popularity in machine learning weather prediction. yet applying transformer architectures to weather forecasting, particularly on a global scale is computationally challenging due to the quadratic complexity of attention and the quadratic increase in spatial points as resolution increases. in this work, we propose a factorized-attention-based model tailored for spherical geometries to mitigate this issue. more specifically, it utilizes multi-dimensional factorized kernels that convolve over different axes where the computational complexity of the kernel is only quadratic to the axial resolution instead of overall resolution. the deterministic forecasting accuracy of the proposed model on $1.5^\circ$ and 0-7 days' lead time is on par with state-of-the-art purely data-driven machine learning weather prediction models. we also showcase the proposed model holds great potential to push forward the pareto front of accuracy-efficiency for transformer weather models, where it can achieve better accuracy with less computational cost compared to transformer based models with standard attention."
"local off-grid weather forecasting with multi-modal earth observation data. urgent applications like wildfire management and renewable energy generation require precise, localized weather forecasts near the earth's surface. however, forecasts produced by machine learning models or numerical weather prediction systems are typically generated on large-scale regular grids, where direct downscaling fails to capture fine-grained, near-surface weather patterns. in this work, we propose a multi-modal transformer model trained end-to-end to downscale gridded forecasts to off-grid locations of interest. our model directly combines local historical weather observations (e.g., wind, temperature, dewpoint) with gridded forecasts to produce locally accurate predictions at various lead times. multiple data modalities are collected and concatenated at station-level locations, treated as a token at each station. using self-attention, the token corresponding to the target location aggregates information from its neighboring tokens. experiments using weather stations across the northeastern united states show that our model outperforms a range of data-driven and non-data-driven off-grid forecasting methods. they also reveal that direct input of station data provides a phase shift in local weather forecasting accuracy, reducing the prediction error by up to 80% compared to pure gridded data based models. this approach demonstrates how to bridge the gap between large-scale weather models and locally accurate forecasts to support high-stakes, location-sensitive decision-making."
"combining distribution-based neural networks to predict weather forecast probabilities. the success of deep learning techniques over the last decades has opened up a new avenue of research for weather forecasting. here, we take the novel approach of using a neural network to predict full probability density functions at each point in space and time rather than a single output value, thus producing a probabilistic weather forecast. this enables the calculation of both uncertainty and skill metrics for the neural network predictions, and overcomes the common difficulty of inferring uncertainty from these predictions. this approach is data-driven and the neural network is trained on the weatherbench dataset (processed era5 data) to forecast geopotential and temperature 3 and 5 days ahead. data exploration leads to the identification of the most important input variables, which are also found to agree with physical reasoning, thereby validating our approach. in order to increase computational efficiency further, each neural network is trained on a small subset of these variables. the outputs are then combined through a stacked neural network, the first time such a technique has been applied to weather data. our approach is found to be more accurate than some numerical weather prediction models and as accurate as more complex alternative neural networks, with the added benefit of providing key probabilistic information necessary for making informed weather forecasts."
