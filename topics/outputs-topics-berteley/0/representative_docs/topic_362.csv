doc
"dynamic-width speculative beam decoding for efficient llm inference. large language models (llms) have shown outstanding performance across numerous real-world tasks. however, the autoregressive nature of these models makes the inference process slow and costly. speculative decoding has emerged as a promising solution, leveraging a smaller auxiliary model to draft future tokens, which are then validated simultaneously by the larger model, achieving a speed-up of 1-2x. although speculative decoding matches the same distribution as multinomial sampling, multinomial sampling itself is prone to suboptimal outputs, whereas beam sampling is widely recognized for producing higher-quality results by maintaining multiple candidate sequences at each step. this paper explores the novel integration of speculative decoding with beam sampling. however, there are four key challenges: (1) how to generate multiple sequences from the larger model's distribution given drafts sequences from the small model; (2) how to dynamically optimize the number of beams to balance efficiency and accuracy; (3) how to efficiently verify the multiple drafts in parallel; and (4) how to address the extra memory costs inherent in beam sampling. to address these challenges, we propose dynamic-width speculative beam decoding (dsbd). specifically, we first introduce a novel draft and verification scheme that generates multiple sequences following the large model's distribution based on beam sampling trajectories from the small model. then, we introduce an adaptive mechanism to dynamically tune the number of beams based on the context, optimizing efficiency and effectiveness. besides, we extend tree-based parallel verification to handle multiple trees simultaneously, accelerating the verification process. finally, we illustrate a simple modification to our algorithm to mitigate the memory overhead of beam sampling..."
"investigating the role of prompting and external tools in hallucination rates of large language models. large language models (llms) are powerful computational models trained on extensive corpora of human-readable text, enabling them to perform general-purpose language understanding and generation. llms have garnered significant attention in both industry and academia due to their exceptional performance across various natural language processing (nlp) tasks. despite these successes, llms often produce inaccuracies, commonly referred to as hallucinations. prompt engineering, the process of designing and formulating instructions for llms to perform specific tasks, has emerged as a key approach to mitigating hallucinations. this paper provides a comprehensive empirical evaluation of different prompting strategies and frameworks aimed at reducing hallucinations in llms. various prompting techniques are applied to a broad set of benchmark datasets to assess the accuracy and hallucination rate of each method. additionally, the paper investigates the influence of tool-calling agents (llms augmented with external tools to enhance their capabilities beyond language generation) on hallucination rates in the same benchmarks. the findings demonstrate that the optimal prompting technique depends on the type of problem, and that simpler techniques often outperform more complex methods in reducing hallucinations. furthermore, it is shown that llm agents can exhibit significantly higher hallucination rates due to the added complexity of external tool usage."
"closer look at efficient inference methods: a survey of speculative decoding. efficient inference in large language models (llms) has become a critical focus as their scale and complexity grow. traditional autoregressive decoding, while effective, suffers from computational inefficiencies due to its sequential token generation process. speculative decoding addresses this bottleneck by introducing a two-stage framework: drafting and verification. a smaller, efficient model generates a preliminary draft, which is then refined by a larger, more sophisticated model. this paper provides a comprehensive survey of speculative decoding methods, categorizing them into draft-centric and model-centric approaches. we discuss key ideas associated with each method, highlighting their potential for scaling llm inference. this survey aims to guide future research in optimizing speculative decoding and its integration into real-world llm applications."
