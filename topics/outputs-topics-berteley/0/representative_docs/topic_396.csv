doc
"on uniform-in-time diffusion approximation for stochastic gradient descent. the diffusion approximation of stochastic gradient descent (sgd) in current literature is only valid on a finite time interval. in this paper, we establish the uniform-in-time diffusion approximation of sgd, by only assuming that the expected loss is strongly convex and some other mild conditions, without assuming the convexity of each random loss function. the main technique is to establish the exponential decay rates of the derivatives of the solution to the backward kolmogorov equation. the uniform-in-time approximation allows us to study asymptotic behaviors of sgd via the continuous stochastic differential equation (sde) even when the random objective function $f(\cdot;\xi)$ is not strongly convex."
"convergence rates and approximation results for sgd and its continuous-time counterpart. this paper proposes a thorough theoretical analysis of stochastic gradient descent (sgd) with non-increasing step sizes. first, we show that the recursion defining sgd can be provably approximated by solutions of a time inhomogeneous stochastic differential equation (sde) using an appropriate coupling. in the specific case of a batch noise we refine our results using recent advances in stein's method. then, motivated by recent analyses of deterministic and stochastic optimization methods by their continuous counterpart, we study the long-time behavior of the continuous processes at hand and establish non-asymptotic bounds. to that purpose, we develop new comparison techniques which are of independent interest. adapting these techniques to the discrete setting, we show that the same results hold for the corresponding sgd sequences. in our analysis, we notably improve non-asymptotic bounds in the convex setting for sgd under weaker assumptions than the ones considered in previous works. finally, we also establish finite-time convergence results under various conditions, including relaxations of the famous {\l}ojasiewicz inequality, which can be applied to a class of non-convex functions."
"parallelizing stochastic gradient descent for least squares regression: mini-batching, averaging, and model misspecification. this work characterizes the benefits of averaging schemes widely used in conjunction with stochastic gradient descent (sgd). in particular, this work provides a sharp analysis of: (1) mini-batching, a method of averaging many samples of a stochastic gradient to both reduce the variance of the stochastic gradient estimate and for parallelizing sgd and (2) tail-averaging, a method involving averaging the final few iterates of sgd to decrease the variance in sgd's final iterate. this work presents non-asymptotic excess risk bounds for these schemes for the stochastic approximation problem of least squares regression. furthermore, this work establishes a precise problem-dependent extent to which mini-batch sgd yields provable near-linear parallelization speedups over sgd with batch size one. this allows for understanding learning rate versus batch size tradeoffs for the final iterate of an sgd method. these results are then utilized in providing a highly parallelizable sgd method that obtains the minimax risk with nearly the same number of serial updates as batch gradient descent, improving significantly over existing sgd methods. a non-asymptotic analysis of communication efficient parallelization schemes such as model-averaging/parameter mixing methods is then provided. finally, this work sheds light on some fundamental differences in sgd's behavior when dealing with agnostic noise in the (non-realizable) least squares regression problem. in particular, the work shows that the stepsizes that ensure minimax risk for the agnostic case must be a function of the noise properties. this paper builds on the operator view of analyzing sgd methods, introduced by defossez and bach (2015), followed by developing a novel analysis in bounding these operators to characterize the excess risk. these techniques are of broader interest in analyzing computational aspects of stochastic approximation."
