doc
consensus function regularization term use adaptive activation function neural network design neural network usually carry define number layer number neuron layer connection synapsis activation function execute training process try optimize weight assign connection bias neuron well fit training datum definition activation function general determine design process modify training mean behavior unrelated training datum set paper propose definition utilization implicit parametric non linear activation function adapt shape training process fact increase space parameter optimize network allow great flexibility generalize concept neural network furthermore simplify architectural design activation function definition employ neuron let training process optimize parameter behavior propose activation function come definition consensus variable optimization linear underdetermined problem regularization term alternate direction method multiplier admm define neural network type activation function preliminary result use neural network type adaptive activation function reduce error regression classification example compare equivalent regular feedforward neural network fix activation function
rate convergence variation constrain deep neural network multi layer feedforward network approximate wide range nonlinear function important fundamental problem understand learnability network model statistical risk expect prediction error future datum good knowledge rate convergence neural network show exist work bound order sample size paper class variation constrain neural network arbitrary width achieve near parametric rate arbitrarily small positive constant equivalent mean square error rate observe numerical experiment result indicate neural function space need approximate smooth function large perceive result provide insight phenomena deep neural network easily suffer overfitte number neuron learn parameter rapidly grow surpass discuss rate convergence network parameter include input dimension network layer coefficient norm
convergence deep neural network general activation function pool deep neural network powerful system represent high dimensional complex function play key role deep learning convergence deep neural network fundamental issue build mathematical foundation deep learning investigate convergence deep relu network deep convolutional neural network recent research rectified linear unit relu activation study important pooling strategy consider current work study convergence deep neural network depth tend infinity important activation function leaky relu sigmoid function pooling study result prove sufficient condition establish sufficient leaky relu network contractive activation function sigmoid function establish weak sufficient condition uniform convergence deep neural network
