doc
visual question answer video quality assessment advent proliferation large multi modal model lmms introduce new paradigm computer vision transform task unified visual question answer framework video quality assessment vqa classic field low level visual perception focus initially quantitative video quality scoring drive advance lmms progress holistic visual quality understanding task recent study image domain demonstrate visual question answer vqa markedly enhance low level visual quality evaluation relate work explore video domain leave substantial room improvement address gap introduce instruction dataset visual question answer instruction dataset focus video quality assessment dataset consist subset cover video type contain instruction question answer pair leverage foundation present series model series model interleave visual motion token enhance perception spatial temporal quality detail video conduct extensive experiment video quality scoring understanding task result demonstrate model achieve excellent performance task notably final model assistant exceed renowned visual quality understand task maintain strong competitiveness quality scoring task work provide foundation feasible approach integrate low level video quality assessment understanding lmms
powerful language model unlock rich visual representation clip foundational multimodal model align image text feature share representation space contrastive learning large scale image text pair effectiveness primarily stem use natural language rich supervision motivate remarkable advancement large language model llm work explore llm superior text understanding extensive open world knowledge enhance clip capability especially processing long complex image caption propose efficient post training strategy integrate llm pretraine clip address challenge pose autoregressive nature llm introduce caption caption contrastive fine tuning framework significantly enhance discriminative quality llm output extensive experiment demonstrate approach outperform lora base method achieve nearly fourfold fast training superior performance furthermore validate substantial improvement state art model clip zero shot multimodal retrieval task cross lingual retrieval task multimodal language model pretraine
generate image multimodal language model propose method fuse frozen text large language model llm pre train image encoder decoder model mapping embed space model demonstrate wide suite multimodal capability image retrieval novel image generation multimodal dialogue approach capable conditioning arbitrarily interleave image text input generate coherent image text output achieve strong performance image generation propose efficient mapping network ground llm shelf text image generation model mapping network translate hide representation text embed space visual model enable leverage strong text representation llm visual output approach outperform baseline generation model task long complex language addition novel image generation model capable image retrieval prespecified dataset decide retrieve generate inference time learn decision module condition hidden representation llm model exhibit wide range capability compare prior multimodal language model process image text input produce retrieve image generate image generate text outperform non llm base generation model text image task measure context dependence
