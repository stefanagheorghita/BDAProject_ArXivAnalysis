doc
"quality of service (qos) modelling in federated cloud computing. building around the idea of a large scale server infrastructure with a potentially large number of tailored resources, which are capable of interacting to facilitate the deployment, adaptation, and support of services, cloud computing needs to frequently reschedule and manage various application tasks in order to accommodate the requests of a wide range and number of users. one of the challenges of cloud computing is to support and manage quality-of-service (qos) by designing efficient techniques for the allocation of tasks between users and the cloud virtual resources, as well as assigning virtual resources to the cloud physical resources. the migration of virtual resources across physical resources is another challenge that requires considerable attention; especially in federated cloud computing environments wherein, providers might be willing to offer their unused resources as a service to the federation (cooperative allocation) and pull back these resources for their own use when they are needed (competitive allocation). this paper revisits the issue of qos in cloud computing by formulating and presenting i) a multi-qos task allocation model for the assignment of tasks to virtual machines and ii) a virtual machine migration model for a federated cloud computing environment by considering cases where resource providers are operating in cooperative or competitive mode. a new differential evolution (de) based binding policy for task allocation and a novel virtual machine model are proposed as solutions for the problem of qos support in federated cloud environments. the experimental results show that the proposed solutions improved the quality of service in the cloud computing environment and reveal the relative advantages of operating a mixed cooperation and competition model in a federated cloud environment."
"energy efficient scheduling for serverless systems. serverless computing, also referred to as function-as-a-service (faas), is a cloud computing model that has attracted significant attention and has been widely adopted in recent years. the serverless computing model offers an intuitive, event-based interface that makes the development and deployment of scalable cloud-based applications easier and cost-effective. an important aspect that has not been examined in these systems is their energy consumption during the application execution. one way to deal with this issue is to schedule the function invocations in an energy-efficient way. however, efficient scheduling of applications in a multi-tenant environment, like faas systems, poses significant challenges. the trade-off between the server's energy usage and the hosted functions' performance requirements needs to be taken into consideration. in this work, we propose an energy efficient scheduler for orchestrating the execution of serverless functions so that it minimizes energy consumption while it satisfies the applications' performance demands. our approach considers real-time performance measurements and historical data and applies a novel dvfs technique to minimize energy consumption. our detailed experimental evaluation using realistic workloads on our local cluster illustrates the working and benefits of our approach."
"engineering and experimentally benchmarking a container-based edge computing system. while edge computing is envisioned to superbly serve latency sensitive applications, the implementation-based studies benchmarking its performance are few and far between. to address this gap, we engineer a modular edge cloud computing system architecture that is built on latest advances in containerization techniques, including kafka, for data streaming, docker, as application platform, and firebase cloud, as realtime database system. we benchmark the performance of the system in terms of scalability, resource utilization and latency by comparing three scenarios: cloud-only, edge-only and combined edge-cloud. the measurements show that edge-only solution outperforms other scenarios only when deployed with data located at one edge only, i.e., without edge computing wide data synchronization. in case of applications requiring data synchronization through the cloud, edge-cloud scales around a factor 10 times better than cloud-only, until certain number of concurrent users in the system, and above this point, cloud-only scales better. in terms of resource utilization, we observe that whereas the mean utilization increases linearly with the number of user requests, the maximum values for the memory and the network i/o heavily increase when with an increasing amount of data."
