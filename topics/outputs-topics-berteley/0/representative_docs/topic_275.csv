doc
"""help me help the ai"": understanding how explainability can support human-ai interaction. despite the proliferation of explainable ai (xai) methods, little is understood about end-users' explainability needs and behaviors around xai explanations. to address this gap and contribute to understanding how explainability can support human-ai interaction, we conducted a mixed-methods study with 20 end-users of a real-world ai application, the merlin bird identification app, and inquired about their xai needs, uses, and perceptions. we found that participants desire practically useful information that can improve their collaboration with the ai, more so than technical system details. relatedly, participants intended to use xai explanations for various purposes beyond understanding the ai's outputs: calibrating trust, improving their task skills, changing their behavior to supply better inputs to the ai, and giving constructive feedback to developers. finally, among existing xai approaches, participants preferred part-based explanations that resemble human reasoning and explanations. we discuss the implications of our findings and provide recommendations for future xai design."
"advancing perception in artificial intelligence through principles of cognitive science. although artificial intelligence (ai) has achieved many feats at a rapid pace, there still exist open problems and fundamental shortcomings related to performance and resource efficiency. since ai researchers benchmark a significant proportion of performance standards through human intelligence, cognitive sciences-inspired ai is a promising domain of research. studying cognitive science can provide a fresh perspective to building fundamental blocks in ai research, which can lead to improved performance and efficiency. in this review paper, we focus on the cognitive functions of perception, which is the process of taking signals from one's surroundings as input, and processing them to understand the environment. particularly, we study and compare its various processes through the lens of both cognitive sciences and ai. through this study, we review all current major theories from various sub-disciplines of cognitive science (specifically neuroscience, psychology and linguistics), and draw parallels with theories and techniques from current practices in ai. we, hence, present a detailed collection of methods in ai for researchers to build ai systems inspired by cognitive science. further, through the process of reviewing the state of cognitive-inspired ai, we point out many gaps in the current state of ai (with respect to the performance of the human brain), and hence present potential directions for researchers to develop better perception systems in ai."
"explainable artificial intelligence techniques for software development lifecycle: a phase-specific survey. artificial intelligence (ai) is rapidly expanding and integrating more into daily life to automate tasks, guide decision making, and enhance efficiency. however, complex ai models, which make decisions without providing clear explanations (known as the ""black-box problem""), currently restrict trust and widespread adoption of ai. explainable artificial intelligence (xai) has emerged to address the black-box problem of making ai systems more interpretable and transparent so stakeholders can trust, verify, and act upon ai-based outcomes. researchers have developed various techniques to foster xai in the software development lifecycle. however, there are gaps in applying xai techniques in the software engineering phases. literature review shows that 68% of xai in software engineering research is focused on maintenance as opposed to 8% on software management and requirements. in this paper, we present a comprehensive survey of the applications of xai methods such as concept-based explanations, local interpretable model-agnostic explanations (lime), shapley additive explanations (shap), rule extraction, attention mechanisms, counterfactual explanations, and example-based explanations to the different phases of the software development life cycle (sdlc), including requirements elicitation, design and development, testing and deployment, and evolution. to the best of our knowledge, this paper presents the first comprehensive survey of xai techniques for every phase of the software development life cycle (sdlc). this survey aims to promote explainable ai in software engineering and facilitate the practical application of complex ai models in ai-driven software development."
