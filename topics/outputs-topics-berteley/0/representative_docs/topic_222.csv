doc
"evolutionary alternating direction method of multipliers for constrained multi-objective optimization with unknown constraints. constrained multi-objective optimization problems (cmops) pervade real-world applications in science, engineering, and design. constraint violation has been a building block in designing evolutionary multi-objective optimization algorithms for solving constrained multi-objective optimization problems. however, in certain scenarios, constraint functions might be unknown or inadequately defined, making constraint violation unattainable and potentially misleading for conventional constrained evolutionary multi-objective optimization algorithms. to address this issue, we present the first of its kind evolutionary optimization framework, inspired by the principles of the alternating direction method of multipliers that decouples objective and constraint functions. this framework tackles cmops with unknown constraints by reformulating the original problem into an additive form of two subproblems, each of which is allotted a dedicated evolutionary population. notably, these two populations operate towards complementary evolutionary directions during their optimization processes. in order to minimize discrepancy, their evolutionary directions alternate, aiding the discovery of feasible solutions. comparative experiments conducted against five state-of-the-art constrained evolutionary multi-objective optimization algorithms, on 120 benchmark test problem instances with varying properties, as well as two real-world engineering optimization problems, demonstrate the effectiveness and superiority of our proposed framework. its salient features include faster convergence and enhanced resilience to various pareto front shapes."
"enhanced opposition differential evolution algorithm for multimodal optimization. most of the real-world problems are multimodal in nature that consists of multiple optimum values. multimodal optimization is defined as the process of finding multiple global and local optima (as opposed to a single solution) of a function. it enables a user to switch between different solutions as per the need while still maintaining the optimal system performance. classical gradient-based methods fail for optimization problems in which the objective functions are either discontinuous or non-differentiable. evolutionary algorithms (eas) are able to find multiple solutions within a population in a single algorithmic run as compared to classical optimization techniques that need multiple restarts and multiple runs to find different solutions. hence, several eas have been proposed to solve such kinds of problems. however, differential evolution (de) algorithm is a population-based heuristic method that can solve such optimization problems, and it is simple to implement. the potential challenge in multi-modal optimization problems (mmops) is to search the function space efficiently to locate most of the peaks accurately. the optimization problem could be to minimize or maximize a given objective function and we aim to solve the maximization problems on multimodal functions in this study. hence, we have proposed an algorithm known as enhanced opposition differential evolution (eode) algorithm to solve the mmops. the proposed algorithm has been tested on ieee congress on evolutionary computation (cec) 2013 benchmark functions, and it achieves competitive results compared to the existing state-of-the-art approaches."
"analysis of evolutionary algorithms in dynamic and stochastic environments. many real-world optimization problems occur in environments that change dynamically or involve stochastic components. evolutionary algorithms and other bio-inspired algorithms have been widely applied to dynamic and stochastic problems. this survey gives an overview of major theoretical developments in the area of runtime analysis for these problems. we review recent theoretical studies of evolutionary algorithms and ant colony optimization for problems where the objective functions or the constraints change over time. furthermore, we consider stochastic problems under various noise models and point out some directions for future research."
