doc
depth estimation matter improve object depth estimation monocular detection tracking monocular image base perception active research area recent year owe application autonomous driving approach monocular perception include detection tracking yield inferior performance compare lidar base technique systematic analysis identify object depth estimation accuracy major factor bound performance motivate observation propose multi level fusion method combine different representation rgb pseudo lidar temporal information multiple frame object tracklet enhance object depth estimation propose fusion method achieve state art performance object depth estimation waymo open dataset kitti detection dataset kitti mot dataset demonstrate simply replace estimate depth fusion enhance depth achieve significant improvement monocular perception task include detection tracking
dimension motion monocular prediction flow subspace introduce way learn estimate scene representation single image predict low dimensional subspace optical flow training example encompass variety possible camera object movement supervision provide novel loss measure distance predict flow subspace observed optical flow provide new approach learn scene representation task monocular depth prediction instance segmentation unsupervised fashion wild input video require camera pose intrinsic explicit multi view stereo step evaluate method multiple setting include indoor depth prediction task achieve comparable performance recent method train supervision
surround monodepth multiple camera self supervise monocular depth ego motion estimation promising approach replace supplement expensive depth sensor lidar robotic application like autonomous driving research area focus single monocular camera stereo pair cover fraction scene vehicle work extend monocular self supervise depth ego motion estimation large baseline multi camera rig generalized spatio temporal contexts pose consistency constraint carefully design photometric loss masking learn single network generate dense consistent scale aware point cloud cover surround degree field view typical lidar scanner propose new scale consistent evaluation metric suitable multi camera setting experiment challenging benchmark illustrate benefit approach strong baseline
