doc
dynamic graph collaborative filtering dynamic recommendation essential modern recommender system provide real time prediction base sequential datum real world scenario popularity item interest user change time base assumption previous work focus interaction sequence learn evolutionary embedding user item argue sequence base model able capture collaborative information user item directly propose dynamic graph collaborative filtering dgcf novel framework leverage dynamic graph capture collaborative sequential relation item user time propose update mechanism zero order inheritance order propagation second order aggregation represent impact user item new interaction occur base update related user item embedding simultaneously interaction occur turn use late embedding recommendation extensive experiment conduct public dataset dgcf significantly outperform state art dynamic recommendation method approach achieve high performance dataset contain action repetition indicate effectiveness integrate dynamic collaborative information
collaborative large language model recommender system recently grow interest develop generation recommender system rss base pretraine large language model llm semantic gap natural language recommendation task address lead multiple issue spuriously correlate user item descriptor ineffective language modeling user item datum inefficient recommendation auto regression etc paper propose generative rs tightly integrate llm paradigm d paradigm rss aim address challenge simultaneously extend vocabulary pretraine llm user item d token faithfully model user item collaborative content semantic accordingly novel prompt strategy propose effectively learn user item collaborative content token embedding language modeling rs specific corpora document split prompt consist heterogeneous soft user item token hard vocab token main text consist homogeneous item token vocab token facilitate stable effective language modeling addition novel mutual regularization strategy introduce encourage capture recommendation relate information noisy user item content finally propose novel recommendation orient finetuning strategy item prediction head multinomial likelihood add pretraine backbone predict hold item base prompt establish mask user item interaction history recommendation multiple item generate efficiently hallucination code release
zero shot item recommendation large pretraine language model large language model llm achieve impressive zero shot performance natural language processing nlp task demonstrate capability inference training example despite success research explore potential llm perform item recommendation zero shot setting identify major challenge address enable llm act effectively recommender recommendation space extremely large llm llm know target user past interact item preference address gap propose prompt strategy call zero shot item recommendation nir prompt direct llm item recommendation specifically nir base strategy involve external module generate candidate item base user filter item filtering strategy incorporate step prompt guide carry subtask capture user preference select representative previously watch movie recommend rank list movie evaluate propose approach movielen dataset achieve strong zero shot performance outperform strong sequential recommendation model train entire training dataset promising result highlight ample research opportunity use llm recommender code find
