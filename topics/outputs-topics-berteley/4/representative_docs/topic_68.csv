doc
flexible communication avoid matrix multiplication fpga high level synthesis datum movement dominate factor affect performance energy modern computing system consequently algorithm develop minimize number o operation common computing pattern matrix multiplication exception low bound prove implement shared distribute memory system reconfigurable hardware platform lucrative target o minimizing algorithm offer control memory access programmer bound develop context fix architecture apply platform spatially distribute nature computational memory resource require decentralized approach optimize algorithm maximum hardware utilization present model optimize matrix multiplication fpga platform simultaneously target maximum performance minimum chip datum movement constraint set hardware map model concrete architecture high level synthesis tool maintain high level abstraction allow support arbitrary datum type enable maintainability portability fpga device kernel generate architecture show offer competitive performance practice scale compute memory resource offer design open source project encourage open development linear algebra o minimize algorithm reconfigurable hardware platform
dalorex data local program execution architecture memory bind application application low datum reuse frequent irregular memory access graph sparse linear algebra workload fail scale memory bottleneck poor core utilization prior work prefetching decouple pipelining mitigate memory latency improve core utilization memory bottleneck persist limited chip bandwidth approach processing memory pim hybrid memory cube hmc overcome bandwidth limitation fail achieve high core utilization poor task scheduling synchronization overhead high memory core ratio available hmc limit strong scaling introduce dalorex hardware software co design achieve high parallelism energy efficiency demonstrate strong scaling core process graph sparse linear algebra workload prior work pim core dalorex improve performance energy consumption order magnitude tile base distribute memory architecture processing tile hold equal datum memory operation local task base parallel programming model task execute processing unit co locate target datum network design optimize irregular traffic communication way message contain routing metadata novel traffic aware task scheduling hardware maintain high core utilization data placement strategy improve work balance work propose architectural software innovation provide great scalability date run graph algorithm programmable domain
modern primer processing memory paper discuss recent research aim enable computation close datum approach broadly processing memory pim pim place computation mechanism near data store inside memory chip module logic layer stack memory memory controller storage device chip data movement computation unit memory storage unit reduce eliminate general idea pim new discuss motivate trend application memory circuit technology greatly exacerbate need enable modern computing system examine promising new approach design pim system accelerate important data intensive application processing memory exploit fundamental analog operational principle memory chip perform massively parallel operation situ memory processing near memory exploit different logic memory integration technology stack memory technology place computation logic close memory circuitry enable high bandwidth low energy low latency access datum approach describe tackle relevant cross layer research design adoption challenge device architecture system compiler programming model application focus development pim design adopt real computing platform low cost conclude discuss work solve key challenge practical adoption pim believe shift processor centric memory centric mindset infrastructure remain large adoption challenge pim overcome unleash fundamentally energy efficient high performance sustainable new way designing programming computing system
