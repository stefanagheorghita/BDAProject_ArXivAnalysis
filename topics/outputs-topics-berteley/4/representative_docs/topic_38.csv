doc
man island fully automatic programming code search code generation program repair automatic programming attempt minimize human intervention generation executable code long stand challenge software engineering community advance automatic programming researcher focus primary direction code search reuse exist code snippet external database code generation produce new code snippet natural language program repair refine exist code snippet fix detect bug despite significant advancement effectiveness state art technique limited usability search code correctness generate code motivate real world programming process developer usually use external tool aid cod process code search engine code testing tool work propose automatic programming framework leverage recent large language model llm integrate research area address inherent limitation particular framework leverage different code search strategy retrieve similar code snippet guide code generation process llm framework validate quality generate code compiler test case construct repair prompt query llm generate correct patch conduct preliminary experiment demonstrate potential framework help codellama solve programming problem improvement generic framework integrate code search generation repair tool combine research area time importantly demonstrate potential traditional se tool enhance usability llm automatic programming
survey evaluate large language model code generation task paper provide comprehensive review current method metric evaluate performance large language model llm code generation task rapid growth demand automate software development llm demonstrate significant potential field code generation paper begin review historical development llm application code generation detail method metric assess code generation capability llm include code correctness efficiency readability evaluation method base expert review user experience paper evaluate widely benchmark dataset identify limitation propose direction future improvement specifically paper analyze performance code generation model different task combine multiple evaluation metric code compilation interpretation success rate unit test pass rate performance efficiency metric comprehensively assess practical application llm code generation finally paper discuss challenge face evaluate llm code generation particularly ensure comprehensiveness accuracy evaluation method adapt evolve practice software development analysis discussion provide valuable insight optimize improve application llm code generation task
large language model code generation practitioner perspective large language model llm emerge cod assistant capable generate source code natural language prompt increase adoption llm software development academic research industry base project develop tool benchmark metric evaluate effectiveness llm generate code lack solution evaluate empirically ground method incorporate practitioner perspective assess functionality syntax accuracy real world application address gap propose develop multi model unified platform generate execute code base natural language prompt conduct survey software practitioner country continent work diverse professional role domain evaluate usability performance strength limitation model result present practitioner feedback insight use llm software development include strength weakness key aspect overlook benchmark metric broad understanding practical applicability finding help researcher practitioner informed decision systematically select llm software development project future research focus integrate diverse model propose system incorporate additional case study conduct developer interview deep empirical insight llm drive software development
