doc
omnidialog omnipotent pre training model task orient dialogue system pre train conversation model pcms demonstrate remarkable result task orient dialogue tod system pcms focus predominantly dialogue management task like dialogue state tracking dialogue generation task like response generation exist pcms seldom consider dialogue comprehension task dialogue question answering summarization task task allow pcms glean dialogue context angle observation naturally raise question performance downstream dialogue task enhance pcm pre train dialogue management generation comprehension task investigate propose omnipotent dialogue pre training model omnidialog unify dialogue task monolithic framework multi task learning foster inter task communication pre training corpus omnidialog span dialogue focus task draw dataset encompass million dialogue utterance knowledge omnidialog pioneer pcm pre train dialogue management generation comprehension domain evaluate performance task dialogue summarization end end dialogue modeling dialogue state tracking intent classification result underscore efficacy domain transfer learning low resource dataset scenario furthermore glean nuanced understanding omnidialog strength potential pitfall design fine grain analysis framework dialogue centric task experimental result omnidialog good hard sample long dialogue lengthy response
sequence sequence learning task orient dialogue dialogue state representation classic pipeline model task orient dialogue system require explicit modeling dialogue state hand craft action space query domain specific knowledge base conversely sequence sequence model learn map dialogue history response current turn explicit knowledge base querying work propose novel framework leverage advantage classic pipeline sequence sequence model framework model dialogue state fix size distribute representation use representation query knowledge base attention mechanism experiment stanford multi turn multi domain task orient dialogue dataset show framework significantly outperform sequence sequence base baseline model automatic human evaluation
precognition task orient dialogue understanding posterior regularization future context task orient dialogue system overwhelmingly popular recent research dialogue understanding widely comprehend user intent emotion dialogue state task orient dialogue system previous work discriminative task model current query historical conversation work entire dialogue flow model suitable real world task orient conversation future context visible case paper propose jointly model historical future information posterior regularization method specifically model current utterance past context prior entire dialogue flow posterior optimize kl distance distribution regularize model training historical information inference extensive experiment dialogue dataset validate effectiveness propose method achieve superior result compare baseline model
