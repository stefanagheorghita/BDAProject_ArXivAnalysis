doc
temporal action localization multi temporal scale temporal action localization play important role video analysis aim localize classify action untrimmed video previous method predict action feature space single temporal scale temporal feature low level scale lack semantic action classification high level scale provide rich detail action boundary address issue propose predict action feature space multi temporal scale specifically use refined feature pyramid different scale pass semantic high level scale low level scale establish long temporal scale entire video use spatial temporal transformer encoder capture long range dependency video frame refined feature long range dependency feed classifier coarse action prediction finally improve prediction accuracy propose use frame level self attention module refine classification boundary action instance extensive experiment propose method outperform state art approach dataset achieve comparable performance dataset compare sub action afsd dataset propose method achieve improvement respectively
procedural generation video train deep action recognition network deep learning human action recognition video make significant progress slow dependency expensive manual labeling large video collection work investigate generation synthetic training datum action recognition recently show promising result variety computer vision task propose interpretable parametric generative model human action video rely procedural generation computer graphic technique modern game engine generate diverse realistic physically plausible dataset human action video call phav procedural human action video contain total video example action category approach limit exist motion capture sequence procedurally define synthetic action introduce deep multi task representation learn architecture mix synthetic real video action category differ experiment benchmark suggest combine large set synthetic video small real world dataset boost recognition performance significantly outperform fine tune state art unsupervised generative model video
unsupervised feature learning human action trajectory pose embed manifold unsupervised human action modeling framework provide useful pose sequence representation utilize variety pose analysis application work propose novel temporal pose sequence modeling framework embed dynamic human skeleton joint continuous latent space efficient manner contrast end end framework explore previous work disentangle task individual pose representation learning task learn action trajectory pose embed space order realize continuous pose embed manifold improved reconstruction propose unsupervised manifold learning procedure name encoder gan engan use pose embedding generate engan model human action bidirectional rnn auto encoder architecture posernn introduce order gradient loss explicitly enforce temporal regularity predict motion sequence hierarchical feature fusion technique investigate simultaneous modeling local skeleton joint global pose variation demonstrate state art transfer ability learn representation supervisedly unsupervisedly learn motion embedding task fine grain action recognition sbu interaction dataset qualitative strength propose framework visualize skeleton pose reconstruction interpolation pose embed space low dimensional principal component projection reconstructed pose trajectory
