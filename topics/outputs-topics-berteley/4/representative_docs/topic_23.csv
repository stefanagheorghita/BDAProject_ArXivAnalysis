doc
improve visual commonsense language model multiple image generation commonsense reasoning fundamentally base multimodal knowledge exist large language model llm primarily train textual datum limit ability incorporate essential visual information contrast visual language model excel visually orient task fail non visual task basic commonsense reasoning divergence highlight critical challenge integration robust visual understanding foundational text base language reasoning end introduce method aim enhance llm visual commonsense specifically method generate multiple image base input text prompt integrate model decision make process mix prediction probability facilitate multimodal ground language modeling employ late fusion layer combine project visual feature output pre train llm condition text late fusion layer enable prediction base comprehensive image text knowledge text require evaluate approach visual commonsense reasoning task traditional nlp task include common sense reasoning reading comprehension experimental result demonstrate significant superiority exist baseline apply recent state art llm observe improvement visual common sense traditional nlp benchmark code model available
multimodal understanding stable diffusion task aware feature extractor recent advance multimodal large language model mllm enable image base question answer capability key limitation use clip visual encoder capture coarse global information miss fine grain detail relevant input query address shortcoming work study pre train text image diffusion model serve instruction aware visual encoder analysis internal representation find diffusion feature rich semantic encode strong image text alignment find leverage text conditioning focus model region relevant input question investigate align feature large language model uncover leakage phenomenon llm inadvertently recover information original diffusion prompt analyze cause leakage propose mitigation strategy base insight explore simple fusion strategy utilize clip conditional diffusion feature evaluate approach general vqa specialized mllm benchmark demonstrate promise diffusion model visual understanding particularly vision centric task require spatial compositional reasoning project page find
generate image multimodal language model propose method fuse frozen text large language model llm pre train image encoder decoder model mapping embed space model demonstrate wide suite multimodal capability image retrieval novel image generation multimodal dialogue approach capable conditioning arbitrarily interleave image text input generate coherent image text output achieve strong performance image generation propose efficient mapping network ground llm shelf text image generation model mapping network translate hide representation text embed space visual model enable leverage strong text representation llm visual output approach outperform baseline generation model task long complex language addition novel image generation model capable image retrieval prespecified dataset decide retrieve generate inference time learn decision module condition hidden representation llm model exhibit wide range capability compare prior multimodal language model process image text input produce retrieve image generate image generate text outperform non llm base generation model text image task measure context dependence
